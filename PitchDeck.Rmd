---
title       : Train Your Model Application
subtitle    : 
author      : Tim Gaertner
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---

## Selecting Training Population

- An important task in any supervised modeling exercise is selecting data to train a model

- The common question for this task is what proportion of the available data should a modeler use to train their model?

- That's where the "Train Your Model" Application comes in to play

- The "Train Your Model" App allows a predictive modeler to efficiently test out training proporitons to see what portion of the data yields the highest accuracy on the test data

- All the user needs to do is enter in different training proportion values and see what happens to the testing accuracy

- With the instant feedback, the modeler can feel confident in the training partition they select

---

## How does it work?

Example: iris data with .5 proportion of the data used for model building

Confusion Matrix Results:
```{r,echo=F,message=F}
library(caret)
library(e1071)
data(iris)
Obs <- iris

model.fn1 <- function(TrainingSize) {
        set.seed(1)
        inTrain <- createDataPartition(y = Obs$Species, 
                                       p=TrainingSize,
                                       list = F)
        training <- Obs[inTrain,]
        testing <- Obs[-inTrain,] 
        
        library(party)
        
        ctreeTune <- ctree(Species ~ ., data=training)
        
        library(caret)
        library(e1071)
        
        confMat <- confusionMatrix(testing$Species,predict(ctreeTune,testing[,-length(names(testing))]))$table
        # create confustion table to display results 
        confusion.matrix = data.frame(confMat[1:3],confMat[4:6],confMat[7:9]) 
        rows <- c("(pred) setosa", "veriscolor", "virginica") 
        cols <- c("(actual) setosa", "veriscolor", "virginica") 
        row.names(confusion.matrix) <- rows 
        colnames(confusion.matrix) <- cols 
              
        confusion.matrix # return confusion table to display 
        
}

model.fn1(.5)
```

Model Accuracy on Test data:
```{r, echo=F,message=F}
model.fn2 <- function(TrainingSize) {
        set.seed(1)
        inTrain <- createDataPartition(y = Obs$Species, 
                                       p=TrainingSize,
                                       list = F)
        training <- Obs[inTrain,]
        testing <- Obs[-inTrain,] 
        
        library(party)
        
        ctreeTune <- ctree(Species ~ ., data=training)
        
        library(caret)
        library(e1071)
        
        confMat <- confusionMatrix(testing$Species,predict(ctreeTune,testing[,-length(names(testing))]))
        confMatAcc <- data.frame(confMat$overall)
        Acc <- round(confMatAcc$confMat.overall[1],3)
        Acc
        
}

model.fn2(.5)
```

---

## How does it work? Cont...

What if we increased the proportion of the data used for model building to .6 instead?

Confusion Matrix Results:
```{r,echo=F,message=F}
library(caret)
library(e1071)
data(iris)
Obs <- iris

model.fn1 <- function(TrainingSize) {
        set.seed(1)
        inTrain <- createDataPartition(y = Obs$Species, 
                                       p=TrainingSize,
                                       list = F)
        training <- Obs[inTrain,]
        testing <- Obs[-inTrain,] 
        
        library(party)
        
        ctreeTune <- ctree(Species ~ ., data=training)
        
        library(caret)
        library(e1071)
        
        confMat <- confusionMatrix(testing$Species,predict(ctreeTune,testing[,-length(names(testing))]))$table
        # create confustion table to display results 
        confusion.matrix = data.frame(confMat[1:3],confMat[4:6],confMat[7:9]) 
        rows <- c("(pred) setosa", "veriscolor", "virginica") 
        cols <- c("(actual) setosa", "veriscolor", "virginica") 
        row.names(confusion.matrix) <- rows 
        colnames(confusion.matrix) <- cols 
              
        confusion.matrix # return confusion table to display 
        
}

model.fn1(.6)
```


Model Accuracy on Test data:
```{r, echo=F,message=F}
model.fn2 <- function(TrainingSize) {
        set.seed(1)
        inTrain <- createDataPartition(y = Obs$Species, 
                                       p=TrainingSize,
                                       list = F)
        training <- Obs[inTrain,]
        testing <- Obs[-inTrain,] 
        
        library(party)
        
        ctreeTune <- ctree(Species ~ ., data=training)
        
        library(caret)
        library(e1071)
        
        confMat <- confusionMatrix(testing$Species,predict(ctreeTune,testing[,-length(names(testing))]))
        confMatAcc <- data.frame(confMat$overall)
        Acc <- round(confMatAcc$confMat.overall[1],3)
        Acc
        
}

model.fn2(.6)
```

- The result is an increase in model accuracy. The modeler might conclude that including more data in the training partition better describes the target classes and it would be wise to allow for a higher training proportion.

---

## Appendix

[Take "Train Your Model" for a Spin](https://timgaertner.shinyapps.io/TrainYourModel)